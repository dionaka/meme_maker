from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Image, Plain
from PIL import Image as PILImage
import io
from pathlib import Path
import cv2
import numpy as np

# å­˜å‚¨ç­‰å¾…å›¾ç‰‡çš„ç”¨æˆ·çŠ¶æ€
waiting_users = {}

@register("meme_maker", "Your Name", "å›¾ç‰‡åˆæˆæ¢—å›¾ç”Ÿæˆå™¨", "1.0.0", "")
class MemeMakerPlugin(Star):
    """æ¢—å›¾ç”Ÿæˆæ’ä»¶"""
    
    def __init__(self, context: Context):
        #åˆå§‹åŒ–
        super().__init__(context)
        
        # æ¨¡æ¿1è·¯å¾„ï¼ˆåŸæœ‰æ¨¡æ¿ï¼‰
        self.template_path = Path(__file__).parent / "template.png"
        # æ¨¡æ¿2è·¯å¾„ï¼ˆæ–°å¢é€æ˜åº•æ¨¡æ¿ï¼‰
        self.template2_path = Path(__file__).parent / "template2.png"
        
        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨
        if not self.template_path.exists():
            logger.error(f"[æ¢—å›¾] âŒ æ¨¡æ¿1ä¸å­˜åœ¨: {self.template_path}")
        else:
            logger.info(f"[æ¢—å›¾] âœ… æ¨¡æ¿1åŠ è½½æˆåŠŸ: {self.template_path}")
            
        if not self.template2_path.exists():
            logger.error(f"[æ¢—å›¾] âŒ æ¨¡æ¿2ä¸å­˜åœ¨: {self.template2_path}")
        else:
            logger.info(f"[æ¢—å›¾] âœ… æ¨¡æ¿2åŠ è½½æˆåŠŸ: {self.template2_path}")
        
        logger.info("æ¢—å›¾ç”Ÿæˆå™¨æ’ä»¶å·²åŠ è½½")
                    
                
    @filter.command("add")
    async def add_command(self, event: AstrMessageEvent):
        """å¤„ç† /add æŒ‡ä»¤ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
        
        # è®°å½•ç”¨æˆ·çŠ¶æ€
        waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add'  # æ ‡è®°ä¸ºæ¨¡å¼1
        }
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šaddï¼‰")
        yield event.plain_result("ğŸ“· è¯·å‘é€å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆæ¢—å›¾ï¼")
    
    @filter.command("add1")
    async def add1_command(self, event: AstrMessageEvent):
        """å¤„ç† /add1 æŒ‡ä»¤ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
        
        # è®°å½•ç”¨æˆ·çŠ¶æ€
        waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add1'  # æ ‡è®°ä¸ºæ¨¡å¼2
        }
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šadd1ï¼‰")
        yield event.plain_result("ğŸ“· è¯·å‘é€å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆæ¢—å›¾ï¼")
    
    @filter.command("add2")
    async def add2_command(self, event: AstrMessageEvent):
        """å¤„ç† /add2 æŒ‡ä»¤ï¼ˆåœ£è¯å¸½åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
    
        # è®°å½•ç”¨æˆ·çŠ¶æ€ï¼Œæ¨¡å¼æ ‡è®°ä¸º 'add2'
        waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add2'  # æ ‡è®°ä¸ºæ¨¡å¼3ï¼Œåœ£è¯å¸½åŠŸèƒ½
        }
    
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šadd2ï¼Œåœ£è¯å¸½ï¼‰")
        yield event.plain_result("ğŸ… è¯·å‘é€ä¸€å¼ åŒ…å«äººè„¸çš„å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä»–/å¥¹æˆ´ä¸Šåœ£è¯å¸½ï¼")

    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        """ç›‘å¬æ‰€æœ‰æ¶ˆæ¯ï¼Œå¤„ç†å›¾ç‰‡"""
        user_id = event.message_obj.sender.user_id
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç­‰å¾…çŠ¶æ€
        if user_id not in waiting_users:
            return
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} åœ¨ç­‰å¾…åˆ—è¡¨ä¸­ï¼Œå¼€å§‹æ£€æŸ¥æ¶ˆæ¯")
        
        # æå–å›¾ç‰‡æ¶ˆæ¯
        images = []
        for idx, seg in enumerate(event.message_obj.message):
            if isinstance(seg, Image):
                images.append(seg)
                logger.info(f"[æ¢—å›¾] æ‰¾åˆ°å›¾ç‰‡æ¶ˆæ¯æ®µ {idx}")
            elif hasattr(seg, 'type') and seg.type == "image":
                images.append(seg)
                logger.info(f"[æ¢—å›¾] æ‰¾åˆ°å›¾ç‰‡æ¶ˆæ¯æ®µ {idx} (é€šè¿‡type)")
        
        if not images:
            logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å‘é€çš„æ¶ˆæ¯ä¸­æ²¡æœ‰å›¾ç‰‡ï¼Œç»§ç»­ç­‰å¾…")
            return
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å‘é€äº† {len(images)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹å¤„ç†")
        
        try:
            # è·å–ç¬¬ä¸€å¼ å›¾ç‰‡
            image_seg = images[0]
            
            # ä¸‹è½½å›¾ç‰‡æ•°æ®
            image_data = None
            
            # å°è¯•å¤šç§æ–¹å¼è·å–å›¾ç‰‡
            if hasattr(image_seg, 'url') and image_seg.url:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» URL ä¸‹è½½: {image_seg.url}")
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    async with session.get(image_seg.url) as resp:
                        if resp.status == 200:
                            image_data = await resp.read()
                            logger.info(f"[æ¢—å›¾] URL ä¸‹è½½æˆåŠŸ: {len(image_data)} å­—èŠ‚")
            
            elif hasattr(image_seg, 'file') and image_seg.file:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» file è¯»å–: {image_seg.file}")
                with open(image_seg.file, 'rb') as f:
                    image_data = f.read()
                    logger.info(f"[æ¢—å›¾] file è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚")
            
            elif hasattr(image_seg, 'path') and image_seg.path:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» path è¯»å–: {image_seg.path}")
                with open(image_seg.path, 'rb') as f:
                    image_data = f.read()
                    logger.info(f"[æ¢—å›¾] path è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚")
            
            elif hasattr(image_seg, 'data'):
                if hasattr(image_seg.data, 'url') and image_seg.data.url:
                    logger.info(f"[æ¢—å›¾] å°è¯•ä» data.url ä¸‹è½½: {image_seg.data.url}")
                    import aiohttp
                    async with aiohttp.ClientSession() as session:
                        async with session.get(image_seg.data.url) as resp:
                            if resp.status == 200:
                                image_data = await resp.read()
                                logger.info(f"[æ¢—å›¾] data.url ä¸‹è½½æˆåŠŸ: {len(image_data)} å­—èŠ‚")
                elif hasattr(image_seg.data, 'file') and image_seg.data.file:
                    logger.info(f"[æ¢—å›¾] å°è¯•ä» data.file è¯»å–: {image_seg.data.file}")
                    with open(image_seg.data.file, 'rb') as f:
                        image_data = f.read()
                        logger.info(f"[æ¢—å›¾] data.file è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚")
            
            if not image_data:
                logger.error(f"[æ¢—å›¾] æ— æ³•è·å–å›¾ç‰‡æ•°æ®ï¼ŒImage å¯¹è±¡å±æ€§: {dir(image_seg)}")
                yield event.plain_result("âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡è¯•")
                del waiting_users[user_id]
                return
            
            logger.info(f"[æ¢—å›¾] å¼€å§‹å¤„ç†å›¾ç‰‡ï¼Œå¤§å°: {len(image_data)} å­—èŠ‚")
            
            # è·å–ç”¨æˆ·æ¨¡å¼
            mode = waiting_users[user_id]['mode']
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
            if mode == 'add':
                # æ£€æŸ¥æ¨¡æ¿1æ˜¯å¦å­˜åœ¨
                if not self.template_path.exists():
                    logger.error(f"[æ¢—å›¾] æ¨¡æ¿1ä¸å­˜åœ¨: {self.template_path}")
                    yield event.plain_result(f"âŒ æ¨¡æ¿å›¾ç‰‡ä¸å­˜åœ¨\nè·¯å¾„: {self.template_path}")
                    del waiting_users[user_id]
                    return
                result_image_data = await self.process_image_mode1(image_data)
            elif mode == 'add1':  # mode == 'add1'
                # æ£€æŸ¥æ¨¡æ¿2æ˜¯å¦å­˜åœ¨
                if not self.template2_path.exists():
                    logger.error(f"[æ¢—å›¾] æ¨¡æ¿2ä¸å­˜åœ¨: {self.template2_path}")
                    yield event.plain_result(f"âŒ æ¨¡æ¿å›¾ç‰‡ä¸å­˜åœ¨\nè·¯å¾„: {self.template2_path}")
                    del waiting_users[user_id]
                    return
                result_image_data = await self.process_image_mode2(image_data)
            else:  # mode == 'add2'
                result_image_data = await self.process_image_mode3(image_data)
            
            
            logger.info(f"[æ¢—å›¾] å›¾ç‰‡å¤„ç†å®Œæˆï¼Œç»“æœå¤§å°: {len(result_image_data)} å­—èŠ‚")
            
            # æ¸…é™¤ç”¨æˆ·çŠ¶æ€
            del waiting_users[user_id]
            logger.info(f"[æ¢—å›¾] å·²æ¸…é™¤ç”¨æˆ· {user_id} çš„ç­‰å¾…çŠ¶æ€")
            
            # è¿”å›å¤„ç†åçš„å›¾ç‰‡
            result_image = Image.fromBytes(result_image_data)
            yield event.chain_result([Plain("âœ… æ¢—å›¾ç”Ÿæˆå®Œæˆï¼\n"), result_image])
            
        except Exception as e:
            logger.error(f"[æ¢—å›¾] å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}", exc_info=True)
            if user_id in waiting_users:
                del waiting_users[user_id]
            yield event.plain_result(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    async def process_image_mode1(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼1ï¼šå°†ç”¨æˆ·å›¾ç‰‡åˆæˆåˆ°æ¨¡æ¿ä¸Šï¼ˆæ™ºèƒ½è£å‰ªå¡«å……ï¼‰
        åŸæœ‰çš„ /add åŠŸèƒ½
        """
        # æ‰“å¼€æ¨¡æ¿å’Œç”¨æˆ·å›¾ç‰‡
        template = PILImage.open(str(self.template_path))
        user_image = PILImage.open(io.BytesIO(user_image_data))
        
        # è½¬æ¢ä¸º RGB æ¨¡å¼
        if user_image.mode != 'RGB' and user_image.mode != 'RGBA':
            user_image = user_image.convert('RGB')
        
        logger.info(f"[æ¢—å›¾] æ¨¡æ¿å°ºå¯¸: {template.size}, ç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}")
        
        # å®šä¹‰ç›®æ ‡åŒºåŸŸ
        target_x = 125
        target_y = 105
        target_width = 400
        target_height = 400
        
        # è£å‰ªå¡«å……æ–¹æ¡ˆ
        scale_x = target_width / user_image.width
        scale_y = target_height / user_image.height
        scale = max(scale_x, scale_y)
        
        new_width = int(user_image.width * scale)
        new_height = int(user_image.height * scale)
        
        user_image = user_image.resize((new_width, new_height), PILImage.Resampling.LANCZOS)
        
        crop_x = (new_width - target_width) // 2
        crop_y = (new_height - target_height) // 2
        
        user_image = user_image.crop((
            crop_x,
            crop_y,
            crop_x + target_width,
            crop_y + target_height
        ))
        
        # ç²˜è´´åˆ°æ¨¡æ¿
        if user_image.mode == 'RGBA':
            template.paste(user_image, (target_x, target_y), user_image)
        else:
            template.paste(user_image, (target_x, target_y))
        
        # ä¿å­˜ç»“æœ
        output = io.BytesIO()
        template.save(output, format='PNG')
        output.seek(0)
        
        return output.read()
    
    async def process_image_mode2(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼2ï¼šå°†é€æ˜åº•æ¨¡æ¿è¦†ç›–åœ¨ç”¨æˆ·å›¾ç‰‡ä¸Š
        æ–°å¢çš„ /add1 åŠŸèƒ½
        
        ç­–ç•¥ï¼š
        1. å°†ç”¨æˆ·å›¾ç‰‡ç­‰æ¯”ç¼©æ”¾åˆ°æ¨¡æ¿å°ºå¯¸ï¼ˆ1990x1918ï¼‰
        2. å°†æ¨¡æ¿ï¼ˆé€æ˜åº•ï¼‰å åŠ åœ¨ç”¨æˆ·å›¾ç‰‡ä¸Š
        """
        # æ‰“å¼€ç”¨æˆ·å›¾ç‰‡å’Œæ¨¡æ¿
        user_image = PILImage.open(io.BytesIO(user_image_data))
        template = PILImage.open(str(self.template2_path))
        
        logger.info(f"[æ¢—å›¾Mode2] ç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}, æ¨¡æ¿å°ºå¯¸: {template.size}")
        
        # è½¬æ¢ç”¨æˆ·å›¾ç‰‡ä¸º RGBA æ¨¡å¼ï¼ˆæ”¯æŒé€æ˜åº¦ï¼‰
        if user_image.mode != 'RGBA':
            user_image = user_image.convert('RGBA')
        
        # ç¡®ä¿æ¨¡æ¿ä¹Ÿæ˜¯ RGBA æ¨¡å¼
        if template.mode != 'RGBA':
            template = template.convert('RGBA')
        
        # è·å–æ¨¡æ¿å°ºå¯¸
        template_width, template_height = template.size
        
        # ğŸ”¥ æ™ºèƒ½ç¼©æ”¾ç”¨æˆ·å›¾ç‰‡åˆ°æ¨¡æ¿å°ºå¯¸ï¼ˆä¿æŒæ¯”ä¾‹ï¼Œè£å‰ªå¡«å……ï¼‰
        scale_x = template_width / user_image.width
        scale_y = template_height / user_image.height
        scale = max(scale_x, scale_y)  # å–å¤§å€¼ç¡®ä¿å¡«æ»¡
        
        new_width = int(user_image.width * scale)
        new_height = int(user_image.height * scale)
        
        logger.info(f"[æ¢—å›¾Mode2] ç¼©æ”¾æ¯”ä¾‹: {scale:.2f}, ç¼©æ”¾åå°ºå¯¸: {new_width}x{new_height}")
        
        # ç¼©æ”¾ç”¨æˆ·å›¾ç‰‡
        user_image = user_image.resize((new_width, new_height), PILImage.Resampling.LANCZOS)
        
        # å±…ä¸­è£å‰ªåˆ°æ¨¡æ¿å°ºå¯¸
        crop_x = (new_width - template_width) // 2
        crop_y = (new_height - template_height) // 2
        
        user_image = user_image.crop((
            crop_x,
            crop_y,
            crop_x + template_width,
            crop_y + template_height
        ))
        
        logger.info(f"[æ¢—å›¾Mode2] æœ€ç»ˆç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}")
        
        # ğŸ”¥ å°†æ¨¡æ¿å åŠ åˆ°ç”¨æˆ·å›¾ç‰‡ä¸Šï¼ˆé€æ˜åº•ä¼šæ˜¾ç¤ºåº•å±‚ç”¨æˆ·å›¾ç‰‡ï¼‰
        # åˆ›å»ºç»“æœç”»å¸ƒ
        result = user_image.copy()
        
        # ä½¿ç”¨ alpha_composite è¿›è¡Œé€æ˜å åŠ 
        result = PILImage.alpha_composite(result, template)
        
        # ä¿å­˜ç»“æœ
        output = io.BytesIO()
        result.save(output, format='PNG')
        output.seek(0)
        
        logger.info("[æ¢—å›¾Mode2] å›¾ç‰‡ä¿å­˜å®Œæˆ")
        return output.read()
        
    async def process_image_mode3(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼3ï¼šè‡ªåŠ¨è¯†åˆ«äººè„¸å¹¶æˆ´ä¸Šåœ£è¯å¸½ï¼
        æ–°å¢çš„ /add2 åŠŸèƒ½
        
        ç­–ç•¥ï¼š
        1. ä½¿ç”¨ DNN / Anime çº§è” / Haar ç­‰å¤šç§äººè„¸æ£€æµ‹ï¼ˆä¼˜å…ˆæ”¯æŒè¾ƒå°åŠ¨æ¼«äººè„¸ï¼‰
        2. ä½¿ç”¨ OpenCV è¿›è¡Œå›¾åƒå¤„ç†å’Œå åŠ åœ£è¯å¸½
        """
        try:
            logger.info("[åœ£è¯å¸½]å¼€å§‹å¤„ç†å›¾ç‰‡ åœ£è¯è€äººæ­£åœ¨åŠ é€Ÿèµ¶æ¥")
            
            # 1. å°†å­—èŠ‚æ•°æ®è½¬åŒ–ä¸º OpenCV å¯å¤„ç†æ ¼å¼
            nparr = np.frombuffer(user_image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError("æ— æ³•è§£ç å›¾ç‰‡æ•°æ®")
            
            # 2. åŠ è½½åœ£è¯å¸½å›¾ç‰‡ (å¸¦é€æ˜é€šé“)
            hat_path = Path(__file__).parent / "christmas_hat.png"
            if not hat_path.exists():
                raise FileNotFoundError(f"åœ£è¯å¸½å›¾ç‰‡æœªæ‰¾åˆ°, ä¸»äººè¯·å°†åœ£è¯å¸½å›¾ç‰‡æ”¹åä¸º `christmas_hat.png` å¹¶æ”¾åœ¨æ’ä»¶ç›®å½•ä¸‹") 
            hat_img = cv2.imread(str(hat_path), cv2.IMREAD_UNCHANGED)
            
            if hat_img is None or hat_img.shape[2] != 4:
                raise ValueError("åœ£è¯å¸½å›¾ç‰‡åŠ è½½å¤±è´¥æˆ–ä¸åŒ…å« Alpha é€šé“ï¼Œè¯·ç¡®ä¿ä¸ºå¸¦é€æ˜é€šé“çš„ PNG å›¾ç‰‡")

            # 3. æ£€æµ‹äººè„¸ï¼ˆé€šç”¨æ–¹æ¡ˆï¼šDNN çœŸäººä¼˜å…ˆ + Anime çº§è” + Haar + å…œåº•ä¸­å¿ƒåŒºåŸŸï¼‰
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            h, w = gray.shape[:2]
            logger.info(f"[åœ£è¯å¸½] åŸå§‹å›¾ç‰‡å°ºå¯¸: {w}x{h}")

            faces = []
            models_dir = Path(__file__).parent / "models"

            # 3.1 ä¼˜å…ˆå°è¯• DNN çœŸäººäººè„¸æ£€æµ‹ï¼ˆéœ€è¦åœ¨ models ç›®å½•ä¸‹æ”¾å¥½ prototxt å’Œ caffemodelï¼‰
            try:
                prototxt_path = models_dir / "deploy.prototxt"
                caffemodel_path = models_dir / "res10_300x300_ssd_iter_140000.caffemodel"

                if prototxt_path.exists() and caffemodel_path.exists():
                    logger.info(f"[åœ£è¯å¸½] ä½¿ç”¨ DNN äººè„¸æ£€æµ‹: {prototxt_path.name}, {caffemodel_path.name}")
                    net = cv2.dnn.readNetFromCaffe(str(prototxt_path), str(caffemodel_path))

                    blob = cv2.dnn.blobFromImage(
                        cv2.resize(img, (300, 300)),
                        1.0,
                        (300, 300),
                        (104.0, 177.0, 123.0)
                    )
                    net.setInput(blob)
                    detections = net.forward()

                    for i in range(detections.shape[2]):
                        confidence = detections[0, 0, i, 2]
                        if confidence < 0.5:
                            continue
                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                        (x1_d, y1_d, x2_d, y2_d) = box.astype("int")
                        x_d = max(0, x1_d)
                        y_d = max(0, y1_d)
                        w_d = min(w, x2_d) - x_d
                        h_d = min(h, y2_d) - y_d
                        if w_d > 0 and h_d > 0:
                            faces.append((x_d, y_d, w_d, h_d))

                    if faces:
                        logger.info(f"[åœ£è¯å¸½] DNN æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸: {faces}")
                else:
                    logger.info("[åœ£è¯å¸½] æœªæ‰¾åˆ° DNN äººè„¸æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡ DNN æ£€æµ‹ï¼ˆå¯åœ¨ models ç›®å½•ä¸‹æ”¾å…¥ deploy.prototxt å’Œ res10_300x300_ssd_iter_140000.caffemodel å¯ç”¨ï¼‰")
            except Exception as dnn_e:
                logger.error(f"[åœ£è¯å¸½] DNN äººè„¸æ£€æµ‹å¤±è´¥: {dnn_e}", exc_info=True)

            # 3.2 è‹¥ DNN æœªæ£€æµ‹åˆ°ï¼Œå†å°è¯• Anime çº§è”æ£€æµ‹ï¼ˆé€‚é…å°å°ºå¯¸åŠ¨æ¼«å¤´åƒï¼‰
            if not faces:
                try:
                    anime_cascade_path = models_dir / "lbpcascade_animeface.xml"
                    if anime_cascade_path.exists():
                        logger.info(f"[åœ£è¯å¸½] ä½¿ç”¨ Anime çº§è”äººè„¸æ£€æµ‹: {anime_cascade_path.name}")
                        anime_cascade = cv2.CascadeClassifier(str(anime_cascade_path))
                        if anime_cascade.empty():
                            logger.error(f"[åœ£è¯å¸½] Anime çº§è”æ¨¡å‹åŠ è½½å¤±è´¥: {anime_cascade_path}")
                        else:
                            # é’ˆå¯¹è¾ƒå°åŠ¨æ¼«è„¸ï¼Œæ”¾å®½æœ€å°å°ºå¯¸å’Œé‚»å±…å‚æ•°
                            min_face = max(int(min(w, h) * 0.03), 20)
                            faces_anime = anime_cascade.detectMultiScale(
                                gray,
                                scaleFactor=1.1,
                                minNeighbors=3,
                                flags=cv2.CASCADE_SCALE_IMAGE,
                                minSize=(min_face, min_face)
                            )
                            if len(faces_anime) > 0:
                                faces = list(faces_anime)
                                logger.info(f"[åœ£è¯å¸½] Anime çº§è”æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸: {faces}")
                    else:
                        logger.info("[åœ£è¯å¸½] æœªæ‰¾åˆ° Anime çº§è”æ¨¡å‹ lbpcascade_animeface.xmlï¼Œå¯æ”¾å…¥ models ç›®å½•ä»¥å¢å¼ºåŠ¨æ¼«å¤´åƒè¯†åˆ«æ•ˆæœ")
                except Exception as anime_e:
                    logger.error(f"[åœ£è¯å¸½] Anime çº§è”äººè„¸æ£€æµ‹å¤±è´¥: {anime_e}", exc_info=True)

            # 3.3 å¦‚å‰ä¸¤ç§ä»æœªæ£€æµ‹åˆ°ï¼Œåˆ™å›é€€åˆ° Haar æ£€æµ‹
            if not faces:
                cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
                face_cascade = cv2.CascadeClassifier(cascade_path)
                if face_cascade.empty():
                    logger.error(f"OpenCV Haar äººè„¸æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {cascade_path}")
                else:
                    logger.info("[åœ£è¯å¸½] ä½¿ç”¨ Haar äººè„¸æ£€æµ‹ä½œä¸ºå›é€€æ–¹æ¡ˆ")
                    # å…è®¸è¯†åˆ«è¾ƒå°äººè„¸ï¼ˆçº¦ä¸ºå›¾åƒå®½/é«˜çš„ 5% èµ·ï¼‰
                    min_face_w = max(int(w * 0.05), 24)
                    min_face_h = max(int(h * 0.05), 24)
                    faces_haar = face_cascade.detectMultiScale(
                        gray,
                        scaleFactor=1.1,
                        minNeighbors=3,
                        flags=cv2.CASCADE_SCALE_IMAGE,
                        minSize=(min_face_w, min_face_h)
                    )
                    faces = list(faces_haar) if len(faces_haar) > 0 else []

            # 3.4 å¦‚æœä»ç„¶æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™å…œåº•ï¼šä»¥å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸä½œä¸ºâ€œäººè„¸åŒºåŸŸâ€
            if not faces:
                logger.warn("[åœ£è¯å¸½] æœªæ£€æµ‹åˆ°äººè„¸ï¼Œå¯ç”¨å…œåº•æ–¹æ¡ˆï¼šä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸæˆ´å¸½å­ï¼ˆé€‚é…åŠ¨æ¼«å¤´åƒ/å…¶ä»–ç”Ÿç‰©ï¼‰")
                fake_w = int(w * 0.5)
                fake_h = int(h * 0.5)
                x_fake = (w - fake_w) // 2
                y_fake = int(h * 0.15)
                faces.append((x_fake, y_fake, fake_w, fake_h))

            logger.info(f"[åœ£è¯å¸½] æœ€ç»ˆç”¨äºæˆ´å¸½å­çš„äººè„¸/åŒºåŸŸæ•°é‡: {len(faces)}ï¼ŒåŒºåŸŸåˆ—è¡¨: {faces}")    
            
            # 5. ä¸ºæ¯å¼ äººè„¸æ·»åŠ åœ£è¯å¸½
            for (x, y, w, h) in faces:
                try:
                    logger.info(f"[åœ£è¯å¸½] å¤„ç†äººè„¸æ¡†: x={x}, y={y}, w={w}, h={h}")
                    # ä»¥äººè„¸çŸ©å½¢ä¸­å¿ƒç‚¹ä½œä¸ºå‚è€ƒï¼ˆç”¨äºå·¦å³å±…ä¸­ï¼‰
                    center_x = x + w // 2
                    # å¤´é¡¶å¤§è‡´ä½ç½® = äººè„¸æ¡†ä¸Šè¾¹å†å¾€ä¸Šåä¸€ç‚¹
                    approx_head_top_y = y - int(h * 0.15)

                    # æ ¹æ®äººè„¸å®½åº¦è®¡ç®—å¸½å­ç¼©æ”¾æ¯”ä¾‹
                    # è¿™é‡Œç¨å¾®æ”¾å¤§ä¸€äº›ï¼Œè®©å¸½å­çœ‹èµ·æ¥æ›´å¤¸å¼ ï¼Œä½†é™åˆ¶æœ€å¤§å°ºå¯¸ï¼Œé¿å…è¶…è¿‡æ•´å¼ å›¾å¤ªå¤š
                    base_scale = w / hat_img.shape[1] * 2.0
                    # å°†ç¼©æ”¾å› å­é™åˆ¶åœ¨ä¸€ä¸ªåˆç†èŒƒå›´
                    hat_scale = max(0.5, min(base_scale, 3.0))

                    hat_width = int(hat_img.shape[1] * hat_scale)
                    hat_height = int(hat_img.shape[0] * hat_scale)

                    # å†æ¬¡æ ¹æ®æ•´å¼ å›¾å°ºå¯¸è¿›è¡Œè£å‰ªé™åˆ¶
                    max_hat_width = img.shape[1] * 2  # ä¸è¶…è¿‡å›¾åƒå®½åº¦çš„ 2 å€
                    max_hat_height = img.shape[0] * 2  # ä¸è¶…è¿‡å›¾åƒé«˜åº¦çš„ 2 å€
                    hat_width = min(hat_width, max_hat_width)
                    hat_height = min(hat_height, max_hat_height)

                    if hat_width <= 0 or hat_height <= 0:
                        logger.warn("[åœ£è¯å¸½] è®¡ç®—å¾—åˆ°çš„å¸½å­å°ºå¯¸æ— æ•ˆï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    resized_hat = cv2.resize(hat_img, (hat_width, hat_height), interpolation=cv2.INTER_AREA)

                    # è®¡ç®—å¸½å­æ”¾ç½®çš„å·¦ä¸Šè§’åæ ‡ï¼š
                    # 1. æ°´å¹³æ–¹å‘ä»¥äººè„¸ä¸­å¿ƒå¯¹é½
                    # 2. å‚ç›´æ–¹å‘ä»¥â€œå¤´é¡¶é™„è¿‘â€ä¸ºå‚è€ƒï¼Œå†è®©å¸½å­ç•¥å¾®ç›–ä½ä¸€ç‚¹å¤´å‘
                    head_center_y_for_hat = approx_head_top_y + int(h * 0.05)
                    x1 = center_x - hat_width // 2
                    y1 = head_center_y_for_hat - hat_height // 2
                    x2 = x1 + hat_width
                    y2 = y1 + hat_height

                    # è‹¥å®Œå…¨åœ¨å›¾å¤–åˆ™è·³è¿‡
                    if x1 >= img.shape[1] or y1 >= img.shape[0] or x2 <= 0 or y2 <= 0:
                        logger.warn("[åœ£è¯å¸½] å¸½å­å®Œå…¨åœ¨å›¾åƒå¤–éƒ¨ï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    # è®¡ç®—å®é™…å¯è§åŒºåŸŸ
                    overlay_x1 = max(0, -x1) if x1 < 0 else 0
                    overlay_y1 = max(0, -y1) if y1 < 0 else 0
                    overlay_x2 = hat_width - max(0, x2 - img.shape[1])
                    overlay_y2 = hat_height - max(0, y2 - img.shape[0])

                    roi_x1 = max(x1, 0)
                    roi_y1 = max(y1, 0)
                    roi_x2 = min(x2, img.shape[1])
                    roi_y2 = min(y2, img.shape[0])

                    if roi_x1 >= roi_x2 or roi_y1 >= roi_y2:
                        logger.warn("[åœ£è¯å¸½] è®¡ç®—å¾—åˆ°çš„ ROI åŒºåŸŸæ— æ•ˆï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    roi = img[roi_y1:roi_y2, roi_x1:roi_x2]

                    # æå–å¸½å­ RGB å’Œ Alpha é€šé“
                    hat_rgb = resized_hat[overlay_y1:overlay_y2, overlay_x1:overlay_x2, :3]
                    alpha_mask = resized_hat[overlay_y1:overlay_y2, overlay_x1:overlay_x2, 3] / 255.0

                    if roi.shape[0] != hat_rgb.shape[0] or roi.shape[1] != hat_rgb.shape[1]:
                        logger.warn(
                            f"[åœ£è¯å¸½] ROI ä¸å¸½å­å°ºå¯¸ä¸åŒ¹é…ï¼Œroi={roi.shape}, hat={hat_rgb.shape}ï¼Œè·³è¿‡è¯¥äººè„¸"
                        )
                        continue

                    # ä½¿ç”¨ Alpha é€šé“è¿›è¡Œèåˆ
                    alpha_mask_3 = np.stack([alpha_mask] * 3, axis=-1)
                    roi[:] = roi * (1 - alpha_mask_3) + hat_rgb * alpha_mask_3

                    img[roi_y1:roi_y2, roi_x1:roi_x2] = roi
                except Exception as face_e:
                    logger.error(f"[åœ£è¯å¸½] å¤„ç†å•ä¸ªäººè„¸æ—¶å‡ºé”™: {face_e}", exc_info=True)
                    # å‡ºé”™æ—¶ä»…è·³è¿‡å½“å‰äººè„¸ï¼Œç»§ç»­å¤„ç†å…¶ä»–äººè„¸
                    continue
            
            # 6. å°†å¤„ç†åçš„ OpenCV å›¾åƒè½¬æ¢å›å­—èŠ‚æ•°æ®
            is_success, buffer = cv2.imencode(".png", img)
            if not is_success:
                raise ValueError("å›¾ç‰‡ç¼–ç å¤±è´¥å–µ")
            logger.info("[åœ£è¯å¸½] å›¾ç‰‡å¤„ç†success")    
            return buffer.tobytes()
        
        except Exception as e:
            logger.error(f"[åœ£è¯å¸½] å¤„ç†å‡ºé”™{e}", exc_info=True)     
            raise   
            
            
            