from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Image, Plain
from PIL import Image as PILImage
import io
from pathlib import Path
import cv2
import numpy as np
import aiohttp
import os
import asyncio
from concurrent.futures import ThreadPoolExecutor

@register("meme_maker", "Your Name", "å›¾ç‰‡åˆæˆæ¢—å›¾ç”Ÿæˆå™¨", "1.0.0", "")
class MemeMakerPlugin(Star):
    """æ¢—å›¾ç”Ÿæˆæ’ä»¶"""
    
    def __init__(self, context: Context):
        #åˆå§‹åŒ–
        super().__init__(context)
        
        # å­˜å‚¨ç­‰å¾…å›¾ç‰‡çš„ç”¨æˆ·çŠ¶æ€ï¼ˆä»å…¨å±€å˜é‡ç§»åˆ°å®ä¾‹å±æ€§ï¼‰
        self.waiting_users = {}
        
        # HTTPä¼šè¯å¤ç”¨ï¼ˆé¿å…é¢‘ç¹åˆ›å»ºå’Œé”€æ¯ï¼‰
        self.http_session = None
        
        # çº¿ç¨‹æ± ç”¨äºæ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
        self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="meme_maker")
        
        # æ¨¡æ¿1è·¯å¾„ï¼ˆåŸæœ‰æ¨¡æ¿ï¼‰
        self.template_path = Path(__file__).parent / "template.png"
        # æ¨¡æ¿2è·¯å¾„ï¼ˆæ–°å¢é€æ˜åº•æ¨¡æ¿ï¼‰
        self.template2_path = Path(__file__).parent / "template2.png"
        # åœ£è¯å¸½è·¯å¾„
        self.hat_path = Path(__file__).parent / "christmas_hat.png"
        # æ¨¡å‹ç›®å½•è·¯å¾„
        self.models_dir = Path(__file__).parent / "models"
        
        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨
        if not self.template_path.exists():
            logger.error(f"[æ¢—å›¾] âŒ æ¨¡æ¿1ä¸å­˜åœ¨: {self.template_path}")
        else:
            logger.info(f"[æ¢—å›¾] âœ… æ¨¡æ¿1åŠ è½½æˆåŠŸ: {self.template_path}")
            
        if not self.template2_path.exists():
            logger.error(f"[æ¢—å›¾] âŒ æ¨¡æ¿2ä¸å­˜åœ¨: {self.template2_path}")
        else:
            logger.info(f"[æ¢—å›¾] âœ… æ¨¡æ¿2åŠ è½½æˆåŠŸ: {self.template2_path}")
        
        # é¢„åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹ï¼ˆé¿å…æ¯æ¬¡å¤„ç†æ—¶é‡å¤åŠ è½½ï¼‰
        self.dnn_net = None
        self.anime_cascade = None
        self.haar_cascade = None
        self.hat_img = None
        
        # åŠ è½½DNNæ¨¡å‹
        prototxt_path = self.models_dir / "deploy.prototxt"
        caffemodel_path = self.models_dir / "res10_300x300_ssd_iter_140000.caffemodel"
        if prototxt_path.exists() and caffemodel_path.exists():
            try:
                self.dnn_net = cv2.dnn.readNetFromCaffe(str(prototxt_path), str(caffemodel_path))
                logger.info(f"[æ¢—å›¾] âœ… DNNäººè„¸æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"[æ¢—å›¾] âŒ DNNæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        else:
            logger.info("[æ¢—å›¾] â„¹ï¸ DNNæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è·³è¿‡DNNæ£€æµ‹")
        
        # åŠ è½½Animeçº§è”åˆ†ç±»å™¨
        anime_cascade_path = self.models_dir / "lbpcascade_animeface.xml"
        if anime_cascade_path.exists():
            try:
                self.anime_cascade = cv2.CascadeClassifier(str(anime_cascade_path))
                if self.anime_cascade.empty():
                    logger.error(f"[æ¢—å›¾] âŒ Animeçº§è”æ¨¡å‹åŠ è½½å¤±è´¥")
                    self.anime_cascade = None
                else:
                    logger.info(f"[æ¢—å›¾] âœ… Animeçº§è”æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"[æ¢—å›¾] âŒ Animeçº§è”æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        else:
            logger.info("[æ¢—å›¾] â„¹ï¸ Animeçº§è”æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è·³è¿‡Animeæ£€æµ‹")
        
        # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ï¼ˆOpenCVå†…ç½®ï¼‰
        try:
            cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            self.haar_cascade = cv2.CascadeClassifier(cascade_path)
            if self.haar_cascade.empty():
                logger.error(f"[æ¢—å›¾] âŒ Haarçº§è”æ¨¡å‹åŠ è½½å¤±è´¥")
                self.haar_cascade = None
            else:
                logger.info(f"[æ¢—å›¾] âœ… Haarçº§è”æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"[æ¢—å›¾] âŒ Haarçº§è”æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        
        # é¢„åŠ è½½åœ£è¯å¸½å›¾ç‰‡
        if self.hat_path.exists():
            try:
                self.hat_img = cv2.imread(str(self.hat_path), cv2.IMREAD_UNCHANGED)
                if self.hat_img is None:
                    logger.error(f"[æ¢—å›¾] âŒ åœ£è¯å¸½å›¾ç‰‡åŠ è½½å¤±è´¥ï¼ˆæ–‡ä»¶å¯èƒ½æŸåï¼‰")
                    self.hat_img = None
                elif len(self.hat_img.shape) < 3 or self.hat_img.shape[2] != 4:
                    logger.error(f"[æ¢—å›¾] âŒ åœ£è¯å¸½å›¾ç‰‡ä¸åŒ…å«Alphaé€šé“ï¼Œéœ€è¦RGBAæ ¼å¼çš„PNGå›¾ç‰‡")
                    self.hat_img = None
                else:
                    logger.info(f"[æ¢—å›¾] âœ… åœ£è¯å¸½å›¾ç‰‡åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"[æ¢—å›¾] âŒ åœ£è¯å¸½å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
                self.hat_img = None
        else:
            logger.info("[æ¢—å›¾] â„¹ï¸ åœ£è¯å¸½å›¾ç‰‡ä¸å­˜åœ¨")
        
        logger.info("æ¢—å›¾ç”Ÿæˆå™¨æ’ä»¶å·²åŠ è½½")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ï¼Œåˆ›å»ºHTTPä¼šè¯"""
        self.http_session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£ï¼Œå…³é—­HTTPä¼šè¯å’Œçº¿ç¨‹æ± """
        if self.http_session:
            await self.http_session.close()
        self.executor.shutdown(wait=True)
                    
                
    @filter.command("add")
    async def add_command(self, event: AstrMessageEvent):
        """å¤„ç† /add æŒ‡ä»¤ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
        
        # è®°å½•ç”¨æˆ·çŠ¶æ€
        self.waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add'  # æ ‡è®°ä¸ºæ¨¡å¼1
        }
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šaddï¼‰")
        yield event.plain_result("ğŸ“· è¯·å‘é€å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆæ¢—å›¾ï¼")
    
    @filter.command("add1")
    async def add1_command(self, event: AstrMessageEvent):
        """å¤„ç† /add1 æŒ‡ä»¤ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
        
        # è®°å½•ç”¨æˆ·çŠ¶æ€
        self.waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add1'  # æ ‡è®°ä¸ºæ¨¡å¼2
        }
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šadd1ï¼‰")
        yield event.plain_result("ğŸ“· è¯·å‘é€å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆæ¢—å›¾ï¼")
    
    @filter.command("add2")
    async def add2_command(self, event: AstrMessageEvent):
        """å¤„ç† /add2 æŒ‡ä»¤ï¼ˆåœ£è¯å¸½åŠŸèƒ½ï¼‰"""
        user_id = event.message_obj.sender.user_id
        session_id = event.unified_msg_origin
    
        # è®°å½•ç”¨æˆ·çŠ¶æ€ï¼Œæ¨¡å¼æ ‡è®°ä¸º 'add2'
        self.waiting_users[user_id] = {
            'session_id': session_id,
            'timestamp': event.message_obj.timestamp,
            'mode': 'add2'  # æ ‡è®°ä¸ºæ¨¡å¼3ï¼Œåœ£è¯å¸½åŠŸèƒ½
        }
    
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å¼€å§‹æ¢—å›¾åˆ¶ä½œæµç¨‹ï¼ˆæ¨¡å¼ï¼šadd2ï¼Œåœ£è¯å¸½ï¼‰")
        yield event.plain_result("ğŸ… è¯·å‘é€ä¸€å¼ åŒ…å«äººè„¸çš„å›¾ç‰‡ï¼Œæˆ‘å°†ä¸ºä»–/å¥¹æˆ´ä¸Šåœ£è¯å¸½ï¼")

    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        """ç›‘å¬æ‰€æœ‰æ¶ˆæ¯ï¼Œå¤„ç†å›¾ç‰‡"""
        user_id = event.message_obj.sender.user_id
        
        # ç¡®ä¿HTTPä¼šè¯å·²åˆ›å»ºä¸”æœªå…³é—­
        if self.http_session is None:
            self.http_session = aiohttp.ClientSession()
        elif hasattr(self.http_session, 'closed') and self.http_session.closed:
            # å¦‚æœä¼šè¯å·²å…³é—­ï¼Œåˆ›å»ºæ–°ä¼šè¯
            self.http_session = aiohttp.ClientSession()
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç­‰å¾…çŠ¶æ€
        if user_id not in self.waiting_users:
            return
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} åœ¨ç­‰å¾…åˆ—è¡¨ä¸­ï¼Œå¼€å§‹æ£€æŸ¥æ¶ˆæ¯")
        
        # æå–å›¾ç‰‡æ¶ˆæ¯
        images = []
        for idx, seg in enumerate(event.message_obj.message):
            if isinstance(seg, Image):
                images.append(seg)
                logger.info(f"[æ¢—å›¾] æ‰¾åˆ°å›¾ç‰‡æ¶ˆæ¯æ®µ {idx}")
            elif hasattr(seg, 'type') and seg.type == "image":
                images.append(seg)
                logger.info(f"[æ¢—å›¾] æ‰¾åˆ°å›¾ç‰‡æ¶ˆæ¯æ®µ {idx} (é€šè¿‡type)")
        
        if not images:
            logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å‘é€çš„æ¶ˆæ¯ä¸­æ²¡æœ‰å›¾ç‰‡ï¼Œç»§ç»­ç­‰å¾…")
            return
        
        logger.info(f"[æ¢—å›¾] ç”¨æˆ· {user_id} å‘é€äº† {len(images)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹å¤„ç†")
        
        try:
            # è·å–ç¬¬ä¸€å¼ å›¾ç‰‡
            image_seg = images[0]
            
            # ä¸‹è½½å›¾ç‰‡æ•°æ®
            image_data = None
            file_size_mb = 0
            
            if hasattr(image_seg, 'url') and image_seg.url:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» URL ä¸‹è½½: {image_seg.url}")
                try:
                    async with self.http_session.get(image_seg.url, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                        if resp.status == 200:
                            # ğŸ”¥ è®°å½•æ–‡ä»¶å¤§å°ï¼Œä½†ä¸é™åˆ¶ï¼ˆåªè¦å›¾ç‰‡å°ºå¯¸è¢«é™åˆ¶ï¼Œå¤§æ–‡ä»¶ä¹Ÿèƒ½å¿«é€Ÿå¤„ç†ï¼‰
                            content_length = resp.headers.get('Content-Length')
                            if content_length:
                                try:
                                    file_size_mb = int(content_length) / 1024 / 1024
                                    logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MBï¼Œå°†ä¸‹è½½å¹¶å¤„ç†")
                                except (ValueError, TypeError):
                                    pass
                            image_data = await resp.read()
                            if not image_data:
                                raise ValueError("ä¸‹è½½çš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
                            logger.info(f"[æ¢—å›¾] URL ä¸‹è½½æˆåŠŸ: {len(image_data)} å­—èŠ‚ ({len(image_data) / 1024 / 1024:.2f}MB)")
                        else:
                            logger.warn(f"[æ¢—å›¾] URLä¸‹è½½å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {resp.status}")
                except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                    logger.error(f"[æ¢—å›¾] URLä¸‹è½½å¼‚å¸¸: {e}")
                    image_data = None
            
            elif hasattr(image_seg, 'file') and image_seg.file:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» file è¯»å–: {image_seg.file}")
                try:
                    if not os.path.exists(image_seg.file):
                        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_seg.file}")
                    file_size = os.path.getsize(image_seg.file)
                    file_size_mb = file_size / 1024 / 1024
                    logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MBï¼Œå°†è¯»å–å¹¶å¤„ç†")
                    with open(image_seg.file, 'rb') as f:
                        image_data = f.read()
                        if not image_data:
                            raise ValueError("è¯»å–çš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
                        logger.info(f"[æ¢—å›¾] file è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚ ({len(image_data) / 1024 / 1024:.2f}MB)")
                except (OSError, IOError, FileNotFoundError) as e:
                    logger.error(f"[æ¢—å›¾] fileè¯»å–å¼‚å¸¸: {e}")
                    image_data = None
            
            elif hasattr(image_seg, 'path') and image_seg.path:
                logger.info(f"[æ¢—å›¾] å°è¯•ä» path è¯»å–: {image_seg.path}")
                try:
                    if not os.path.exists(image_seg.path):
                        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_seg.path}")
                    file_size = os.path.getsize(image_seg.path)
                    file_size_mb = file_size / 1024 / 1024
                    logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MBï¼Œå°†è¯»å–å¹¶å¤„ç†")
                    with open(image_seg.path, 'rb') as f:
                        image_data = f.read()
                        if not image_data:
                            raise ValueError("è¯»å–çš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
                        logger.info(f"[æ¢—å›¾] path è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚ ({len(image_data) / 1024 / 1024:.2f}MB)")
                except (OSError, IOError, FileNotFoundError) as e:
                    logger.error(f"[æ¢—å›¾] pathè¯»å–å¼‚å¸¸: {e}")
                    image_data = None
            
            elif hasattr(image_seg, 'data'):
                if hasattr(image_seg.data, 'url') and image_seg.data.url:
                    logger.info(f"[æ¢—å›¾] å°è¯•ä» data.url ä¸‹è½½: {image_seg.data.url}")
                    try:
                        async with self.http_session.get(image_seg.data.url, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                            if resp.status == 200:
                                # ğŸ”¥ è®°å½•æ–‡ä»¶å¤§å°ï¼Œä½†ä¸é™åˆ¶
                                content_length = resp.headers.get('Content-Length')
                                if content_length:
                                    try:
                                        file_size_mb = int(content_length) / 1024 / 1024
                                        logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MBï¼Œå°†ä¸‹è½½å¹¶å¤„ç†")
                                    except (ValueError, TypeError):
                                        pass
                                image_data = await resp.read()
                                if not image_data:
                                    raise ValueError("ä¸‹è½½çš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
                                logger.info(f"[æ¢—å›¾] data.url ä¸‹è½½æˆåŠŸ: {len(image_data)} å­—èŠ‚ ({len(image_data) / 1024 / 1024:.2f}MB)")
                            else:
                                logger.warn(f"[æ¢—å›¾] data.urlä¸‹è½½å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {resp.status}")
                    except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                        logger.error(f"[æ¢—å›¾] data.urlä¸‹è½½å¼‚å¸¸: {e}")
                        image_data = None
                elif hasattr(image_seg.data, 'file') and image_seg.data.file:
                    logger.info(f"[æ¢—å›¾] å°è¯•ä» data.file è¯»å–: {image_seg.data.file}")
                    try:
                        if not os.path.exists(image_seg.data.file):
                            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_seg.data.file}")
                        file_size = os.path.getsize(image_seg.data.file)
                        file_size_mb = file_size / 1024 / 1024
                        logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MBï¼Œå°†è¯»å–å¹¶å¤„ç†")
                        with open(image_seg.data.file, 'rb') as f:
                            image_data = f.read()
                            if not image_data:
                                raise ValueError("è¯»å–çš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
                            logger.info(f"[æ¢—å›¾] data.file è¯»å–æˆåŠŸ: {len(image_data)} å­—èŠ‚ ({len(image_data) / 1024 / 1024:.2f}MB)")
                    except (OSError, IOError, FileNotFoundError) as e:
                        logger.error(f"[æ¢—å›¾] data.fileè¯»å–å¼‚å¸¸: {e}")
                        image_data = None
            
            if not image_data:
                # åªè¾“å‡ºå…³é”®å±æ€§ï¼Œé¿å…è¾“å‡ºæ•´ä¸ªdir()åˆ—è¡¨
                attrs_info = []
                for attr in ['url', 'file', 'path', 'data', 'type']:
                    if hasattr(image_seg, attr):
                        value = getattr(image_seg, attr)
                        if value:
                            attrs_info.append(f"{attr}={str(value)[:100]}")  # é™åˆ¶é•¿åº¦é¿å…è¾“å‡ºè¿‡é•¿
                logger.error(f"[æ¢—å›¾] æ— æ³•è·å–å›¾ç‰‡æ•°æ®ï¼ŒImageå¯¹è±¡å…³é”®å±æ€§: {', '.join(attrs_info) if attrs_info else 'æ— '}")
                yield event.plain_result("âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡è¯•")
                del self.waiting_users[user_id]
                return
            
            # ğŸ”¥ æ³¨æ„ï¼šä¸é™åˆ¶æ–‡ä»¶å¤§å°ï¼Œä½†ä¼šé™åˆ¶å›¾ç‰‡å°ºå¯¸ï¼ˆåƒç´ ï¼‰ï¼Œç¡®ä¿å¤„ç†é€Ÿåº¦
            # åªè¦å›¾ç‰‡å°ºå¯¸è¢«é™åˆ¶åœ¨2000åƒç´ ä»¥å†…ï¼Œå³ä½¿æ–‡ä»¶å¾ˆå¤§ä¹Ÿèƒ½å¿«é€Ÿå¤„ç†
            file_size_mb = len(image_data) / 1024 / 1024
            logger.info(f"[æ¢—å›¾] å¼€å§‹å¤„ç†å›¾ç‰‡ï¼Œæ–‡ä»¶å¤§å°: {len(image_data)} å­—èŠ‚ ({file_size_mb:.2f}MB)")
            
            # ğŸ”¥ æå‰æ£€æŸ¥å›¾ç‰‡å°ºå¯¸ï¼ˆä»…ç”¨äºæ—¥å¿—è®°å½•ï¼Œä¸æ‹’ç»å¤„ç†ï¼‰
            temp_img = None
            try:
                temp_img = PILImage.open(io.BytesIO(image_data))
                temp_img.verify()  # éªŒè¯å›¾ç‰‡å®Œæ•´æ€§
                temp_img.close()  # å…³é—­ç¬¬ä¸€æ¬¡æ‰“å¼€çš„å›¾ç‰‡
                temp_img = PILImage.open(io.BytesIO(image_data))  # é‡æ–°æ‰“å¼€ï¼ˆverifyåéœ€è¦é‡æ–°æ‰“å¼€ï¼‰
                img_width, img_height = temp_img.size
                
                MAX_DIMENSION = 2000
                if max(img_width, img_height) > MAX_DIMENSION:
                    logger.info(f"[æ¢—å›¾] æ£€æµ‹åˆ°å›¾ç‰‡å°ºå¯¸è¾ƒå¤§ ({img_width}x{img_height})ï¼Œå°†åœ¨å¤„ç†æ—¶è‡ªåŠ¨ç¼©å°åˆ°åˆç†å°ºå¯¸")
            except Exception as size_check_e:
                logger.warn(f"[æ¢—å›¾] å›¾ç‰‡å°ºå¯¸æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­å¤„ç†: {size_check_e}")
            finally:
                if temp_img:
                    try:
                        temp_img.close()
                    except:
                        pass
            
            # è·å–ç”¨æˆ·æ¨¡å¼ï¼ˆå†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«åˆ é™¤ï¼‰
            if user_id not in self.waiting_users:
                logger.warn(f"[æ¢—å›¾] ç”¨æˆ· {user_id} çš„ç­‰å¾…çŠ¶æ€åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«æ¸…é™¤")
                return
            mode = self.waiting_users[user_id].get('mode')
            if not mode:
                logger.error(f"[æ¢—å›¾] ç”¨æˆ· {user_id} çš„æ¨¡å¼ä¿¡æ¯ç¼ºå¤±")
                del self.waiting_users[user_id]
                yield event.plain_result("âŒ å¤„ç†å¤±è´¥ï¼šæ¨¡å¼ä¿¡æ¯ç¼ºå¤±")
                return
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
            if mode == 'add':
                # æ£€æŸ¥æ¨¡æ¿1æ˜¯å¦å­˜åœ¨
                if not self.template_path.exists():
                    logger.error(f"[æ¢—å›¾] æ¨¡æ¿1ä¸å­˜åœ¨: {self.template_path}")
                    yield event.plain_result(f"âŒ æ¨¡æ¿å›¾ç‰‡ä¸å­˜åœ¨\nè·¯å¾„: {self.template_path}")
                    del self.waiting_users[user_id]
                    return
                result_image_data = await self.process_image_mode1(image_data)
            elif mode == 'add1':  # mode == 'add1'
                # æ£€æŸ¥æ¨¡æ¿2æ˜¯å¦å­˜åœ¨
                if not self.template2_path.exists():
                    logger.error(f"[æ¢—å›¾] æ¨¡æ¿2ä¸å­˜åœ¨: {self.template2_path}")
                    yield event.plain_result(f"âŒ æ¨¡æ¿å›¾ç‰‡ä¸å­˜åœ¨\nè·¯å¾„: {self.template2_path}")
                    del self.waiting_users[user_id]
                    return
                result_image_data = await self.process_image_mode2(image_data)
            else:  # mode == 'add2'
                result_image_data = await self.process_image_mode3(image_data)
            
            # æ£€æŸ¥å¤„ç†ç»“æœ
            if not result_image_data or len(result_image_data) == 0:
                raise ValueError("å›¾ç‰‡å¤„ç†å¤±è´¥ï¼šè¿”å›æ•°æ®ä¸ºç©º")
            
            logger.info(f"[æ¢—å›¾] å›¾ç‰‡å¤„ç†å®Œæˆï¼Œç»“æœå¤§å°: {len(result_image_data)} å­—èŠ‚")
            
            # æ¸…é™¤ç”¨æˆ·çŠ¶æ€
            del self.waiting_users[user_id]
            logger.info(f"[æ¢—å›¾] å·²æ¸…é™¤ç”¨æˆ· {user_id} çš„ç­‰å¾…çŠ¶æ€")
            
            # è¿”å›å¤„ç†åçš„å›¾ç‰‡
            # ğŸ”¥ é¿å…è¾“å‡ºå›¾ç‰‡æ•°æ®åˆ°æ§åˆ¶å°ï¼Œåªè®°å½•å¤§å°
            result_size_mb = len(result_image_data) / 1024 / 1024
            logger.info(f"[æ¢—å›¾] å›¾ç‰‡å¤„ç†å®Œæˆï¼Œç»“æœå¤§å°: {len(result_image_data)} å­—èŠ‚ ({result_size_mb:.2f}MB)ï¼Œå‡†å¤‡å‘é€")
            
            # åˆ›å»ºå›¾ç‰‡å¯¹è±¡ï¼ˆæ¡†æ¶å¯èƒ½ä¼šè¾“å‡ºï¼Œä½†æˆ‘ä»¬å·²ç»é™åˆ¶äº†æ—¥å¿—ï¼‰
            if not result_image_data or len(result_image_data) == 0:
                raise ValueError("å¤„ç†åçš„å›¾ç‰‡æ•°æ®ä¸ºç©º")
            try:
                result_image = Image.fromBytes(result_image_data)
                yield event.chain_result([Plain("âœ… æ¢—å›¾ç”Ÿæˆå®Œæˆï¼\n"), result_image])
            except Exception as img_e:
                logger.error(f"[æ¢—å›¾] åˆ›å»ºå›¾ç‰‡å¯¹è±¡å¤±è´¥: {img_e}")
                raise ValueError(f"æ— æ³•åˆ›å»ºå›¾ç‰‡å¯¹è±¡: {img_e}")
            
        except Exception as e:
            # åªè¾“å‡ºå¼‚å¸¸ä¿¡æ¯ï¼Œä¸è¾“å‡ºå®Œæ•´å †æ ˆï¼ˆé¿å…è¾“å‡ºè¿‡å¤šå†…å®¹ï¼‰
            logger.error(f"[æ¢—å›¾] å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            # å¦‚æœéœ€è¦è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼Œå¯ä»¥ä¸´æ—¶å¯ç”¨ exc_info=True
            # logger.error(f"[æ¢—å›¾] å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}", exc_info=True)
            if user_id in self.waiting_users:
                del self.waiting_users[user_id]
            yield event.plain_result(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    def _process_image_mode1_sync(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼1ï¼šå°†ç”¨æˆ·å›¾ç‰‡åˆæˆåˆ°æ¨¡æ¿ä¸Šï¼ˆæ™ºèƒ½è£å‰ªå¡«å……ï¼‰- åŒæ­¥ç‰ˆæœ¬ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
        åŸæœ‰çš„ /add åŠŸèƒ½
        """
        # æ‰“å¼€æ¨¡æ¿å’Œç”¨æˆ·å›¾ç‰‡
        template = None
        user_image = None
        try:
            template = PILImage.open(str(self.template_path))
            user_image = PILImage.open(io.BytesIO(user_image_data))
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šå¦‚æœå›¾ç‰‡è¿‡å¤§ï¼Œå…ˆç¼©å°åˆ°åˆç†å°ºå¯¸ï¼ˆæœ€å¤§è¾¹2000åƒç´ ï¼‰å¹¶ä½¿ç”¨å¿«é€Ÿç®—æ³•
            MAX_DIMENSION = 2000
            if max(user_image.size) > MAX_DIMENSION:
                scale = MAX_DIMENSION / max(user_image.size)
                new_size = (int(user_image.width * scale), int(user_image.height * scale))
                logger.info(f"[æ¢—å›¾] å›¾ç‰‡è¿‡å¤§ ({user_image.size})ï¼Œå…ˆç¼©å°åˆ° {new_size} ä»¥ä¼˜åŒ–æ€§èƒ½")
                # ä½¿ç”¨BILINEARè€Œä¸æ˜¯LANCZOSï¼Œé€Ÿåº¦æ›´å¿«
                user_image = user_image.resize(new_size, PILImage.Resampling.BILINEAR)
            
            # è½¬æ¢ä¸º RGB æ¨¡å¼
            if user_image.mode != 'RGB' and user_image.mode != 'RGBA':
                user_image = user_image.convert('RGB')
            
            logger.info(f"[æ¢—å›¾] æ¨¡æ¿å°ºå¯¸: {template.size}, ç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}")
            
            # å®šä¹‰ç›®æ ‡åŒºåŸŸ
            target_x = 125
            target_y = 105
            target_width = 400
            target_height = 400
            
            # è£å‰ªå¡«å……æ–¹æ¡ˆ
            if user_image.width <= 0 or user_image.height <= 0:
                raise ValueError(f"ç”¨æˆ·å›¾ç‰‡å°ºå¯¸æ— æ•ˆ: {user_image.size}")
            scale_x = target_width / user_image.width
            scale_y = target_height / user_image.height
            scale = max(scale_x, scale_y)
            
            new_width = int(user_image.width * scale)
            new_height = int(user_image.height * scale)
            
            # ä½¿ç”¨BILINEARç®—æ³•ï¼Œé€Ÿåº¦æ›´å¿«
            user_image = user_image.resize((new_width, new_height), PILImage.Resampling.BILINEAR)
            
            crop_x = (new_width - target_width) // 2
            crop_y = (new_height - target_height) // 2
            
            user_image = user_image.crop((
                crop_x,
                crop_y,
                crop_x + target_width,
                crop_y + target_height
            ))
            
            # ç²˜è´´åˆ°æ¨¡æ¿
            if user_image.mode == 'RGBA':
                template.paste(user_image, (target_x, target_y), user_image)
            else:
                template.paste(user_image, (target_x, target_y))
            
            # ä¿å­˜ç»“æœï¼Œä¼˜åŒ–è¾“å‡ºå¤§å°
            output = io.BytesIO()
            # å¦‚æœç»“æœå›¾ç‰‡è¿‡å¤§ï¼Œä½¿ç”¨ä¼˜åŒ–å‚æ•°å‹ç¼©
            if max(template.size) > 2000:
                template.save(output, format='PNG', optimize=True, compress_level=6)
            else:
                template.save(output, format='PNG', optimize=True)
            output.seek(0)
            
            return output.read()
        finally:
            # æ˜¾å¼å…³é—­èµ„æºï¼Œé¿å…å†…å­˜æ³„æ¼
            if template:
                template.close()
            if user_image:
                user_image.close()
    
    async def process_image_mode1(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼1ï¼šå°†ç”¨æˆ·å›¾ç‰‡åˆæˆåˆ°æ¨¡æ¿ä¸Šï¼ˆæ™ºèƒ½è£å‰ªå¡«å……ï¼‰
        åŸæœ‰çš„ /add åŠŸèƒ½
        """
        # å°†CPUå¯†é›†å‹ä»»åŠ¡æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(self.executor, self._process_image_mode1_sync, user_image_data)
    
    def _process_image_mode2_sync(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼2ï¼šå°†é€æ˜åº•æ¨¡æ¿è¦†ç›–åœ¨ç”¨æˆ·å›¾ç‰‡ä¸Š - åŒæ­¥ç‰ˆæœ¬ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
        æ–°å¢çš„ /add1 åŠŸèƒ½
        
        ç­–ç•¥ï¼š
        1. å°†ç”¨æˆ·å›¾ç‰‡ç­‰æ¯”ç¼©æ”¾åˆ°æ¨¡æ¿å°ºå¯¸ï¼ˆ1990x1918ï¼‰
        2. å°†æ¨¡æ¿ï¼ˆé€æ˜åº•ï¼‰å åŠ åœ¨ç”¨æˆ·å›¾ç‰‡ä¸Š
        """
        # æ‰“å¼€ç”¨æˆ·å›¾ç‰‡å’Œæ¨¡æ¿
        user_image = None
        template = None
        try:
            user_image = PILImage.open(io.BytesIO(user_image_data))
        
            # ğŸ”¥ ä¼˜åŒ–ï¼šå¦‚æœå›¾ç‰‡è¿‡å¤§ï¼Œå…ˆç¼©å°åˆ°åˆç†å°ºå¯¸ï¼ˆæœ€å¤§è¾¹2000åƒç´ ï¼‰å¹¶ä½¿ç”¨å¿«é€Ÿç®—æ³•
            MAX_DIMENSION = 2000
            if max(user_image.size) > MAX_DIMENSION:
                scale = MAX_DIMENSION / max(user_image.size)
                new_size = (int(user_image.width * scale), int(user_image.height * scale))
                logger.info(f"[æ¢—å›¾Mode2] å›¾ç‰‡è¿‡å¤§ ({user_image.size})ï¼Œå…ˆç¼©å°åˆ° {new_size} ä»¥ä¼˜åŒ–æ€§èƒ½")
                # ä½¿ç”¨BILINEARè€Œä¸æ˜¯LANCZOSï¼Œé€Ÿåº¦æ›´å¿«
                user_image = user_image.resize(new_size, PILImage.Resampling.BILINEAR)
            
            template = PILImage.open(str(self.template2_path))
        
            logger.info(f"[æ¢—å›¾Mode2] ç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}, æ¨¡æ¿å°ºå¯¸: {template.size}")
            
            # è½¬æ¢ç”¨æˆ·å›¾ç‰‡ä¸º RGBA æ¨¡å¼ï¼ˆæ”¯æŒé€æ˜åº¦ï¼‰
            if user_image.mode != 'RGBA':
                user_image = user_image.convert('RGBA')
            
            # ç¡®ä¿æ¨¡æ¿ä¹Ÿæ˜¯ RGBA æ¨¡å¼
            if template.mode != 'RGBA':
                template = template.convert('RGBA')
            
            # è·å–æ¨¡æ¿å°ºå¯¸
            template_width, template_height = template.size
            
            # ğŸ”¥ æ™ºèƒ½ç¼©æ”¾ç”¨æˆ·å›¾ç‰‡åˆ°æ¨¡æ¿å°ºå¯¸ï¼ˆä¿æŒæ¯”ä¾‹ï¼Œè£å‰ªå¡«å……ï¼‰
            if user_image.width <= 0 or user_image.height <= 0:
                raise ValueError(f"ç”¨æˆ·å›¾ç‰‡å°ºå¯¸æ— æ•ˆ: {user_image.size}")
            if template_width <= 0 or template_height <= 0:
                raise ValueError(f"æ¨¡æ¿å°ºå¯¸æ— æ•ˆ: {template.size}")
            scale_x = template_width / user_image.width
            scale_y = template_height / user_image.height
            scale = max(scale_x, scale_y)  # å–å¤§å€¼ç¡®ä¿å¡«æ»¡
            
            new_width = int(user_image.width * scale)
            new_height = int(user_image.height * scale)
            
            logger.info(f"[æ¢—å›¾Mode2] ç¼©æ”¾æ¯”ä¾‹: {scale:.2f}, ç¼©æ”¾åå°ºå¯¸: {new_width}x{new_height}")
            
            # ç¼©æ”¾ç”¨æˆ·å›¾ç‰‡ï¼Œä½¿ç”¨BILINEARç®—æ³•ï¼Œé€Ÿåº¦æ›´å¿«
            user_image = user_image.resize((new_width, new_height), PILImage.Resampling.BILINEAR)
            
            # å±…ä¸­è£å‰ªåˆ°æ¨¡æ¿å°ºå¯¸
            crop_x = (new_width - template_width) // 2
            crop_y = (new_height - template_height) // 2
            
            user_image = user_image.crop((
                crop_x,
                crop_y,
                crop_x + template_width,
                crop_y + template_height
            ))
            
            logger.info(f"[æ¢—å›¾Mode2] æœ€ç»ˆç”¨æˆ·å›¾ç‰‡å°ºå¯¸: {user_image.size}")
            
            # ğŸ”¥ å°†æ¨¡æ¿å åŠ åˆ°ç”¨æˆ·å›¾ç‰‡ä¸Šï¼ˆé€æ˜åº•ä¼šæ˜¾ç¤ºåº•å±‚ç”¨æˆ·å›¾ç‰‡ï¼‰
            # åˆ›å»ºç»“æœç”»å¸ƒ
            result = user_image.copy()
            
            # ä½¿ç”¨ alpha_composite è¿›è¡Œé€æ˜å åŠ 
            result = PILImage.alpha_composite(result, template)
            
            # ä¿å­˜ç»“æœï¼Œä¼˜åŒ–è¾“å‡ºå¤§å°
            output = io.BytesIO()
            # å¦‚æœç»“æœå›¾ç‰‡è¿‡å¤§ï¼Œä½¿ç”¨ä¼˜åŒ–å‚æ•°å‹ç¼©
            if max(result.size) > 2000:
                result.save(output, format='PNG', optimize=True, compress_level=6)
            else:
                result.save(output, format='PNG', optimize=True)
            output.seek(0)
            
            logger.info("[æ¢—å›¾Mode2] å›¾ç‰‡ä¿å­˜å®Œæˆ")
            return output.read()
        finally:
            # æ˜¾å¼å…³é—­èµ„æºï¼Œé¿å…å†…å­˜æ³„æ¼
            if user_image:
                user_image.close()
            if template:
                template.close()
    
    async def process_image_mode2(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼2ï¼šå°†é€æ˜åº•æ¨¡æ¿è¦†ç›–åœ¨ç”¨æˆ·å›¾ç‰‡ä¸Š
        æ–°å¢çš„ /add1 åŠŸèƒ½
        """
        # å°†CPUå¯†é›†å‹ä»»åŠ¡æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(self.executor, self._process_image_mode2_sync, user_image_data)
        
    def _detect_faces(self, img, gray, h, w):
        """
        æ£€æµ‹äººè„¸ - ä½¿ç”¨é¢„åŠ è½½çš„æ¨¡å‹
        è¿”å›äººè„¸åˆ—è¡¨
        """
        faces = []
        
        # 3.1 ä¼˜å…ˆå°è¯• DNN çœŸäººäººè„¸æ£€æµ‹
        if self.dnn_net is not None:
            try:
                logger.info("[åœ£è¯å¸½] ä½¿ç”¨é¢„åŠ è½½çš„ DNN äººè„¸æ£€æµ‹")
                blob = cv2.dnn.blobFromImage(
                    cv2.resize(img, (300, 300)),
                    1.0,
                    (300, 300),
                    (104.0, 177.0, 123.0)
                )
                self.dnn_net.setInput(blob)
                detections = self.dnn_net.forward()

                for i in range(detections.shape[2]):
                    confidence = detections[0, 0, i, 2]
                    if confidence < 0.5:
                        continue
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (x1_d, y1_d, x2_d, y2_d) = box.astype("int")
                    x_d = max(0, x1_d)
                    y_d = max(0, y1_d)
                    w_d = min(w, x2_d) - x_d
                    h_d = min(h, y2_d) - y_d
                    if w_d > 0 and h_d > 0:
                        faces.append((x_d, y_d, w_d, h_d))

                if faces:
                    logger.info(f"[åœ£è¯å¸½] DNN æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸: {faces}")
            except Exception as dnn_e:
                logger.error(f"[åœ£è¯å¸½] DNN äººè„¸æ£€æµ‹å¤±è´¥: {dnn_e}", exc_info=True)

        # 3.2 è‹¥ DNN æœªæ£€æµ‹åˆ°ï¼Œå†å°è¯• Anime çº§è”æ£€æµ‹
        if not faces and self.anime_cascade is not None:
            try:
                logger.info("[åœ£è¯å¸½] ä½¿ç”¨é¢„åŠ è½½çš„ Anime çº§è”äººè„¸æ£€æµ‹")
                # é’ˆå¯¹è¾ƒå°åŠ¨æ¼«è„¸ï¼Œæ”¾å®½æœ€å°å°ºå¯¸å’Œé‚»å±…å‚æ•°
                min_face = max(int(min(w, h) * 0.03), 20)
                faces_anime = self.anime_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=3,
                    flags=cv2.CASCADE_SCALE_IMAGE,
                    minSize=(min_face, min_face)
                )
                if len(faces_anime) > 0:
                    faces = list(faces_anime)
                    logger.info(f"[åœ£è¯å¸½] Anime çº§è”æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸: {faces}")
            except Exception as anime_e:
                logger.error(f"[åœ£è¯å¸½] Anime çº§è”äººè„¸æ£€æµ‹å¤±è´¥: {anime_e}", exc_info=True)

        # 3.3 å¦‚å‰ä¸¤ç§ä»æœªæ£€æµ‹åˆ°ï¼Œåˆ™å›é€€åˆ° Haar æ£€æµ‹
        if not faces and self.haar_cascade is not None:
            try:
                logger.info("[åœ£è¯å¸½] ä½¿ç”¨é¢„åŠ è½½çš„ Haar äººè„¸æ£€æµ‹ä½œä¸ºå›é€€æ–¹æ¡ˆ")
                # å…è®¸è¯†åˆ«è¾ƒå°äººè„¸ï¼ˆçº¦ä¸ºå›¾åƒå®½/é«˜çš„ 5% èµ·ï¼‰
                min_face_w = max(int(w * 0.05), 24)
                min_face_h = max(int(h * 0.05), 24)
                faces_haar = self.haar_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=3,
                    flags=cv2.CASCADE_SCALE_IMAGE,
                    minSize=(min_face_w, min_face_h)
                )
                faces = list(faces_haar) if len(faces_haar) > 0 else []
            except Exception as haar_e:
                logger.error(f"[åœ£è¯å¸½] Haar äººè„¸æ£€æµ‹å¤±è´¥: {haar_e}", exc_info=True)

        # 3.4 å¦‚æœä»ç„¶æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™å…œåº•ï¼šä»¥å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸä½œä¸º"äººè„¸åŒºåŸŸ"
        if not faces:
            logger.warn("[åœ£è¯å¸½] æœªæ£€æµ‹åˆ°äººè„¸ï¼Œå¯ç”¨å…œåº•æ–¹æ¡ˆï¼šä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸæˆ´å¸½å­ï¼ˆé€‚é…åŠ¨æ¼«å¤´åƒ/å…¶ä»–ç”Ÿç‰©ï¼‰")
            fake_w = int(w * 0.5)
            fake_h = int(h * 0.5)
            x_fake = (w - fake_w) // 2
            y_fake = int(h * 0.15)
            faces.append((x_fake, y_fake, fake_w, fake_h))

        return faces
    
    def _process_image_mode3_sync(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼3ï¼šè‡ªåŠ¨è¯†åˆ«äººè„¸å¹¶æˆ´ä¸Šåœ£è¯å¸½ï¼- åŒæ­¥ç‰ˆæœ¬ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
        æ–°å¢çš„ /add2 åŠŸèƒ½
        
        ç­–ç•¥ï¼š
        1. ä½¿ç”¨ DNN / Anime çº§è” / Haar ç­‰å¤šç§äººè„¸æ£€æµ‹ï¼ˆä¼˜å…ˆæ”¯æŒè¾ƒå°åŠ¨æ¼«äººè„¸ï¼‰
        2. ä½¿ç”¨ OpenCV è¿›è¡Œå›¾åƒå¤„ç†å’Œå åŠ åœ£è¯å¸½
        """
        try:
            logger.info("[åœ£è¯å¸½]å¼€å§‹å¤„ç†å›¾ç‰‡ åœ£è¯è€äººæ­£åœ¨åŠ é€Ÿèµ¶æ¥")
            
            # æ£€æŸ¥åœ£è¯å¸½å›¾ç‰‡æ˜¯å¦å·²åŠ è½½
            if self.hat_img is None:
                raise FileNotFoundError("åœ£è¯å¸½å›¾ç‰‡æœªåŠ è½½ï¼Œè¯·ç¡®ä¿ christmas_hat.png å­˜åœ¨äºæ’ä»¶ç›®å½•")
            
            # æ£€æŸ¥åœ£è¯å¸½å›¾ç‰‡æ ¼å¼
            if len(self.hat_img.shape) < 3 or self.hat_img.shape[2] != 4:
                raise ValueError("åœ£è¯å¸½å›¾ç‰‡æ ¼å¼ä¸æ­£ç¡®ï¼Œéœ€è¦åŒ…å«Alphaé€šé“çš„PNGå›¾ç‰‡")
            
            # 1. å°†å­—èŠ‚æ•°æ®è½¬åŒ–ä¸º OpenCV å¯å¤„ç†æ ¼å¼
            if not user_image_data or len(user_image_data) == 0:
                raise ValueError("å›¾ç‰‡æ•°æ®ä¸ºç©º")
            nparr = np.frombuffer(user_image_data, np.uint8)
            if len(nparr) == 0:
                raise ValueError("å›¾ç‰‡æ•°æ®è§£ç å¤±è´¥")
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError("æ— æ³•è§£ç å›¾ç‰‡æ•°æ®")
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šå¦‚æœå›¾ç‰‡è¿‡å¤§ï¼Œå…ˆç¼©å°åˆ°åˆç†å°ºå¯¸ï¼ˆæœ€å¤§è¾¹2000åƒç´ ï¼‰ä»¥é¿å…å¡æ­»å’Œå†…å­˜æº¢å‡º
            MAX_DIMENSION = 2000
            h, w = img.shape[:2]
            if max(w, h) > MAX_DIMENSION:
                scale = MAX_DIMENSION / max(w, h)
                new_w = int(w * scale)
                new_h = int(h * scale)
                logger.info(f"[åœ£è¯å¸½] å›¾ç‰‡è¿‡å¤§ ({w}x{h})ï¼Œå…ˆç¼©å°åˆ° {new_w}x{new_h} ä»¥ä¼˜åŒ–æ€§èƒ½")
                # ä½¿ç”¨INTER_LINEARè€Œä¸æ˜¯INTER_AREAï¼Œé€Ÿåº¦æ›´å¿«
                img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            # 2. ä½¿ç”¨é¢„åŠ è½½çš„åœ£è¯å¸½å›¾ç‰‡
            hat_img = self.hat_img.copy()  # å¤åˆ¶ä¸€ä»½ï¼Œé¿å…ä¿®æ”¹åŸå§‹å›¾ç‰‡
            
            # 3. æ£€æµ‹äººè„¸ï¼ˆä½¿ç”¨é¢„åŠ è½½çš„æ¨¡å‹ï¼‰
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            h, w = gray.shape[:2]
            logger.info(f"[åœ£è¯å¸½] å¤„ç†å›¾ç‰‡å°ºå¯¸: {w}x{h}")

            faces = self._detect_faces(img, gray, h, w)
            logger.info(f"[åœ£è¯å¸½] æœ€ç»ˆç”¨äºæˆ´å¸½å­çš„äººè„¸/åŒºåŸŸæ•°é‡: {len(faces)}ï¼ŒåŒºåŸŸåˆ—è¡¨: {faces}")    
            
            # 4. ä¸ºæ¯å¼ äººè„¸æ·»åŠ åœ£è¯å¸½
            for (x, y, w, h) in faces:
                try:
                    logger.info(f"[åœ£è¯å¸½] å¤„ç†äººè„¸æ¡†: x={x}, y={y}, w={w}, h={h}")
                    # ä»¥äººè„¸çŸ©å½¢ä¸­å¿ƒç‚¹ä½œä¸ºå‚è€ƒï¼ˆç”¨äºå·¦å³å±…ä¸­ï¼‰
                    center_x = x + w // 2
                    # å¤´é¡¶å¤§è‡´ä½ç½® = äººè„¸æ¡†ä¸Šè¾¹å†å¾€ä¸Šåä¸€ç‚¹
                    approx_head_top_y = y - int(h * 0.15)

                    # æ ¹æ®äººè„¸å®½åº¦è®¡ç®—å¸½å­ç¼©æ”¾æ¯”ä¾‹
                    # è¿™é‡Œç¨å¾®æ”¾å¤§ä¸€äº›ï¼Œè®©å¸½å­çœ‹èµ·æ¥æ›´å¤¸å¼ ï¼Œä½†é™åˆ¶æœ€å¤§å°ºå¯¸ï¼Œé¿å…è¶…è¿‡æ•´å¼ å›¾å¤ªå¤š
                    if hat_img.shape[1] <= 0:
                        logger.warn("[åœ£è¯å¸½] åœ£è¯å¸½å›¾ç‰‡å®½åº¦æ— æ•ˆï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue
                    base_scale = w / hat_img.shape[1] * 2.0
                    # å°†ç¼©æ”¾å› å­é™åˆ¶åœ¨ä¸€ä¸ªåˆç†èŒƒå›´
                    hat_scale = max(0.5, min(base_scale, 3.0))

                    hat_width = int(hat_img.shape[1] * hat_scale)
                    hat_height = int(hat_img.shape[0] * hat_scale)

                    # å†æ¬¡æ ¹æ®æ•´å¼ å›¾å°ºå¯¸è¿›è¡Œè£å‰ªé™åˆ¶
                    max_hat_width = img.shape[1] * 2  # ä¸è¶…è¿‡å›¾åƒå®½åº¦çš„ 2 å€
                    max_hat_height = img.shape[0] * 2  # ä¸è¶…è¿‡å›¾åƒé«˜åº¦çš„ 2 å€
                    hat_width = min(hat_width, max_hat_width)
                    hat_height = min(hat_height, max_hat_height)

                    if hat_width <= 0 or hat_height <= 0:
                        logger.warn("[åœ£è¯å¸½] è®¡ç®—å¾—åˆ°çš„å¸½å­å°ºå¯¸æ— æ•ˆï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    # ä½¿ç”¨INTER_LINEARè€Œä¸æ˜¯INTER_AREAï¼Œé€Ÿåº¦æ›´å¿«
                    resized_hat = cv2.resize(hat_img, (hat_width, hat_height), interpolation=cv2.INTER_LINEAR)

                    # è®¡ç®—å¸½å­æ”¾ç½®çš„å·¦ä¸Šè§’åæ ‡ï¼š
                    # 1. æ°´å¹³æ–¹å‘ä»¥äººè„¸ä¸­å¿ƒå¯¹é½
                    # 2. å‚ç›´æ–¹å‘ä»¥"å¤´é¡¶é™„è¿‘"ä¸ºå‚è€ƒï¼Œå†è®©å¸½å­ç•¥å¾®ç›–ä½ä¸€ç‚¹å¤´å‘
                    head_center_y_for_hat = approx_head_top_y + int(h * 0.05)
                    x1 = center_x - hat_width // 2
                    y1 = head_center_y_for_hat - hat_height // 2
                    x2 = x1 + hat_width
                    y2 = y1 + hat_height

                    # è‹¥å®Œå…¨åœ¨å›¾å¤–åˆ™è·³è¿‡
                    if x1 >= img.shape[1] or y1 >= img.shape[0] or x2 <= 0 or y2 <= 0:
                        logger.warn("[åœ£è¯å¸½] å¸½å­å®Œå…¨åœ¨å›¾åƒå¤–éƒ¨ï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    # è®¡ç®—å®é™…å¯è§åŒºåŸŸ
                    overlay_x1 = max(0, -x1) if x1 < 0 else 0
                    overlay_y1 = max(0, -y1) if y1 < 0 else 0
                    overlay_x2 = hat_width - max(0, x2 - img.shape[1])
                    overlay_y2 = hat_height - max(0, y2 - img.shape[0])

                    roi_x1 = max(x1, 0)
                    roi_y1 = max(y1, 0)
                    roi_x2 = min(x2, img.shape[1])
                    roi_y2 = min(y2, img.shape[0])

                    if roi_x1 >= roi_x2 or roi_y1 >= roi_y2:
                        logger.warn("[åœ£è¯å¸½] è®¡ç®—å¾—åˆ°çš„ ROI åŒºåŸŸæ— æ•ˆï¼Œè·³è¿‡è¯¥äººè„¸")
                        continue

                    roi = img[roi_y1:roi_y2, roi_x1:roi_x2]

                    # æå–å¸½å­ RGB å’Œ Alpha é€šé“
                    hat_rgb = resized_hat[overlay_y1:overlay_y2, overlay_x1:overlay_x2, :3]
                    alpha_mask = resized_hat[overlay_y1:overlay_y2, overlay_x1:overlay_x2, 3] / 255.0

                    if roi.shape[0] != hat_rgb.shape[0] or roi.shape[1] != hat_rgb.shape[1]:
                        logger.warn(
                            f"[åœ£è¯å¸½] ROI ä¸å¸½å­å°ºå¯¸ä¸åŒ¹é…ï¼Œroi={roi.shape}, hat={hat_rgb.shape}ï¼Œè·³è¿‡è¯¥äººè„¸"
                        )
                        continue

                    # ä½¿ç”¨ Alpha é€šé“è¿›è¡Œèåˆ
                    alpha_mask_3 = np.stack([alpha_mask] * 3, axis=-1)
                    roi[:] = roi * (1 - alpha_mask_3) + hat_rgb * alpha_mask_3

                    img[roi_y1:roi_y2, roi_x1:roi_x2] = roi
                except Exception as face_e:
                    logger.error(f"[åœ£è¯å¸½] å¤„ç†å•ä¸ªäººè„¸æ—¶å‡ºé”™: {face_e}", exc_info=True)
                    # å‡ºé”™æ—¶ä»…è·³è¿‡å½“å‰äººè„¸ï¼Œç»§ç»­å¤„ç†å…¶ä»–äººè„¸
                    continue
            
            # 5. å°†å¤„ç†åçš„ OpenCV å›¾åƒè½¬æ¢å›å­—èŠ‚æ•°æ®
            # ä½¿ç”¨å‹ç¼©å‚æ•°ä¼˜åŒ–è¾“å‡ºå¤§å°
            encode_params = [cv2.IMWRITE_PNG_COMPRESSION, 6]  # å‹ç¼©çº§åˆ«0-9ï¼Œ6æ˜¯å¹³è¡¡å€¼
            is_success, buffer = cv2.imencode(".png", img, encode_params)
            if not is_success:
                raise ValueError("å›¾ç‰‡ç¼–ç å¤±è´¥å–µ")
            logger.info(f"[åœ£è¯å¸½] å›¾ç‰‡å¤„ç†successï¼Œè¾“å‡ºå¤§å°: {len(buffer)} å­—èŠ‚")    
            return buffer.tobytes()
        
        except Exception as e:
            logger.error(f"[åœ£è¯å¸½] å¤„ç†å‡ºé”™{e}", exc_info=True)     
            raise
    
    async def process_image_mode3(self, user_image_data: bytes) -> bytes:
        """
        æ¨¡å¼3ï¼šè‡ªåŠ¨è¯†åˆ«äººè„¸å¹¶æˆ´ä¸Šåœ£è¯å¸½ï¼
        æ–°å¢çš„ /add2 åŠŸèƒ½
        """
        # å°†CPUå¯†é›†å‹ä»»åŠ¡æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(self.executor, self._process_image_mode3_sync, user_image_data)   
            
            
            